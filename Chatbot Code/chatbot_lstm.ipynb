{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3-tMPsxRVrt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, GlobalMaxPooling1D, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYCQRwycSZR9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load the JSON file\n",
        "with open('intents.json') as file:  #type it whith your folder location of the dataset \n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mS8L53OfSqlX"
      },
      "outputs": [],
      "source": [
        "tags = []\n",
        "patterns = []\n",
        "responses = {}\n",
        "for intent in data['intents']:\n",
        "  responses[intent['tag']]= intent['responses']\n",
        "  for lines in intent['patterns']:\n",
        "    patterns.append(lines)\n",
        "    tags.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14VPf1h_T5Ug"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame({\"patterns\": patterns,\n",
        "                     \"tags\": tags})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rSQEukoCXM4z",
        "outputId": "5dff3a25-3457-473f-8c02-b696e5950927"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87fTdgo0XSNo"
      },
      "outputs": [],
      "source": [
        "#Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzlOVtpqXU2-"
      },
      "outputs": [],
      "source": [
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cDnVsElkXWty",
        "outputId": "19903e5c-3c9b-4135-d3b6-2ecccf04f6d9"
      },
      "outputs": [],
      "source": [
        "data['patterns'] = data['patterns'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation]) #remove punctuation and lowercase\n",
        "data['patterns'] = data['patterns'].apply(lambda wrd: ''.join(wrd))\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1HA66SxXgNG"
      },
      "outputs": [],
      "source": [
        "#tokenize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EibB9pZuYApj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(data['patterns'])\n",
        "\n",
        "train = tokenizer.texts_to_sequences(data['patterns'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCJ__4ZUYu4g"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Icur83zY5-t"
      },
      "outputs": [],
      "source": [
        "# encoding the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyWCuGz8Y7gL"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(data['tags'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6TARss3ZWqe",
        "outputId": "3f1fafc1-e2f3-4abc-f40b-4bf45073fb98"
      },
      "outputs": [],
      "source": [
        "input_shape = x_train.shape[1]\n",
        "print(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el79yFuLZfnh",
        "outputId": "40865bc2-f691-4288-b1b3-665d7493c302"
      },
      "outputs": [],
      "source": [
        "# define the vocab\n",
        "vocabulary = len(tokenizer.word_index)\n",
        "print(\"number of unique words\", vocabulary)\n",
        "output_length = le.classes_.shape[0]\n",
        "print(\"output length\", output_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jf4ZHKmWZ6Wh"
      },
      "outputs": [],
      "source": [
        " # neural network LSTM\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "i = Input(shape=(input_shape,))\n",
        "x = Embedding(vocabulary+1, 10)(i)\n",
        "x = LSTM(10, return_sequences = True)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(output_length, activation = \"softmax\")(x)\n",
        "model = Model(i,x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXNartxhak6w"
      },
      "outputs": [],
      "source": [
        "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HxOQFUWa4lf",
        "outputId": "72e7bfe4-68bd-40d9-9c88-3e7153139756"
      },
      "outputs": [],
      "source": [
        "train = model.fit(x_train, y_train, epochs = 1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhOVAQMpbf1u"
      },
      "outputs": [],
      "source": [
        "# accuracy plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Jj0Lbp9sbpTs",
        "outputId": "3725bdd2-c9fe-4563-e29f-50b546d8ee95"
      },
      "outputs": [],
      "source": [
        "plt.plot(train.history['accuracy'], label = 'training set accuracy')\n",
        "plt.plot(train.history['loss'], label = 'training set loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb3NhGQOb_wK"
      },
      "outputs": [],
      "source": [
        "# chatting\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfCeS8jteAof"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6z9dT6bcB_4",
        "outputId": "95d048c3-0044-494d-c398-c5e76afd7b2f"
      },
      "outputs": [],
      "source": [
        "while True:\n",
        "  texts_p = []\n",
        "  prediction_input = input('You')\n",
        "\n",
        "  # remove punct and convert to lowrcase4\n",
        "  prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "  prediction_input = ''.join(prediction_input)\n",
        "  texts_p.append(prediction_input)\n",
        "\n",
        "  # token and padding\n",
        "  prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "  prediction_input = np.array(prediction_input).reshape(-1)\n",
        "  prediction_input = pad_sequences([prediction_input], input_shape)\n",
        "\n",
        "  # getting output\n",
        "  output = model.predict(prediction_input)\n",
        "  output = output.argmax()\n",
        "\n",
        "  # finding the right tag and predict\n",
        "  response_tag = le.inverse_transform([output])[0]\n",
        "  print(\"curhat's boot : \", random.choice(responses[response_tag]))\n",
        "  if response_tag == \"goodbye\":\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFDvZcDOezyE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYX0_qWkcLnN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
